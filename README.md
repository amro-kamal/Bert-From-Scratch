# Bert From Scratch
My Implementation for BERT [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
](https://arxiv.org/abs/1810.04805). The implementation is in pytorch.

Still not Completed!

Currently the implementation includes:

- [x] Encoder
- [x] Encoder Layer
- [x] Encoder Head
- [x] Positionsal Encoding
- [x] Segement Embedding 

## TODO
- [ ] Bert Trainer
- [ ] MLM dataloader


[//]: # (This is a comment.)
